import pandas as pd
import time
import requests
from urllib.parse import urlparse

API_KEY = "AIzaSyDpyU2fCvNTwaDJNx2uUd0v8QeKUJsfV_Y"
SEARCH_ENGINE_ID = "1302a3cde8de3429a"
INPUT_CSV = "hoteles_para_google.csv"
OUTPUT_CSV = "procesamiento_google.csv"

# Cargar datos
df = pd.read_csv(INPUT_CSV)

# AÃ±adir columnas de URL si no existen
for i in range(1, 11):
    col = f"url_{i}"
    if col not in df.columns:
        df[col] = ""
    df[col] = df[col].astype(str) # Previene errores al guardar strings

def buscar_urls_google(query, max_urls=10):
    urls = []
    dominios = set()
    try:
        for start in range(1, 30, 10):  # PaginaciÃ³n (mÃ¡ximo 30 resultados: 3 pÃ¡ginas)
            url = (
                "https://www.googleapis.com/customsearch/v1?"
                f"key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}&start={start}"
            )
            res = requests.get(url)
            if res.status_code != 200:
                print(f"âŒ Error HTTP: {res.status_code}")
                break
            resultados = res.json().get("items", [])
            for r in resultados:
                enlace = r.get("link")
                if enlace:
                    dominio = urlparse(enlace).netloc
                    if dominio not in dominios:
                        dominios.add(dominio)
                        urls.append(enlace)
                if len(urls) >= max_urls:
                    break
            if len(urls) >= max_urls:
                break
    except Exception as e:
        print(f"âŒ Error en bÃºsqueda: {e}")
    return urls

# Iterar sobre hoteles
for idx, row in df.iterrows():
    if pd.isna(row["url_principal"]):
        query = f"{row['nombre']}, {row['ciudad']}, {row['pais']}"
        print(f"ğŸ” Buscando URLs con Google para: {query}")
        urls = buscar_urls_google(query)

        for i, url in enumerate(urls):
            df.at[idx, f"url_{i+1}"] = url
        if urls:
            print(f"âœ… {len(urls)} URLs encontradas y guardadas.")
        else:
            print("âš ï¸ Ninguna URL encontrada.")
        time.sleep(5)  # Espera corta para evitar lÃ­mite de cuota

    if idx % 10 == 0:
        df.to_csv(OUTPUT_CSV, index=False)
        print(f"ğŸ’¾ Progreso guardado en fila {idx}")

# Guardado final
df.to_csv(OUTPUT_CSV, index=False)
print("ğŸ‰ Proceso completo.")
